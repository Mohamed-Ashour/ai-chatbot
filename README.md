# ğŸ¤– Full-Stack AI Chatbot

A modern, production-ready AI chatbot application featuring real-time messaging, session persistence, and AI-powered responses. Built with FastAPI backend, Next.js frontend, and Redis-based message streaming architecture.

## ğŸ¢ï¸ Architecture

This is a **microservices architecture** with three main components:

```
fullstack-ai-chatbot/
â”œâ”€â”€ server/                # FastAPI API Server
â”‚   â”œâ”€â”€ main.py            # FastAPI app with CORS
â”‚   â”œâ”€â”€ src/               # Source code
â”‚   â”‚   â”œâ”€â”€ routes/        # API routes (token, chat_history, websocket)
â”‚   â”‚   â”œâ”€â”€ redis/         # Redis integration (streams, cache)
â”‚   â”‚   â”œâ”€â”€ socket/        # WebSocket management & token validation
â”‚   â”‚   â””â”€â”€ schema/        # Pydantic data models
â”‚   â”œâ”€â”€ start_server.sh    # Server startup script
â”‚   â””â”€â”€ requirements.txt   # Python dependencies
â”‚
â”œâ”€â”€ worker/                # AI Processing Worker
â”‚   â”œâ”€â”€ main.py            # Worker process for AI responses
â”‚   â”œâ”€â”€ src/               # Source code
â”‚   â”‚   â”œâ”€â”€ model/         # AI model integration (GPT)
â”‚   â”‚   â”œâ”€â”€ redis/         # Redis streams & cache
â”‚   â”‚   â””â”€â”€ schema/        # Shared data models
â”‚   â””â”€â”€ requirements.txt   # Python dependencies
â”‚
â””â”€â”€ client/                # Next.js Frontend
    â”œâ”€â”€ src/               # Source code
    â”‚   â”œâ”€â”€ app/           # Next.js app directory
    â”‚   â”œâ”€â”€ components/    # React components
    â”‚   â”œâ”€â”€ hooks/         # Custom React hooks (useChat)
    â”‚   â”œâ”€â”€ lib/           # Utilities & session management
    â”‚   â””â”€â”€ types/         # TypeScript types
    â”œâ”€â”€ start_client.sh    # Client startup script
    â””â”€â”€ package.json       # Node.js dependencies
```

### ğŸ“‹ Data Flow
1. **Client** sends message via WebSocket â†’ **Server**
2. **Server** publishes to Redis stream â†’ **Worker**
3. **Worker** processes with AI model â†’ publishes response â†’ **Server**
4. **Server** sends AI response â†’ **Client**
5. **Worker** stores both messages in Redis for chat history

## âœ¨ Features

### ğŸš€ Core Functionality
- ğŸ¤– **AI-Powered Responses** - Real AI model integration with GPT
- âš¡ **Real-time Messaging** - Instant WebSocket communication
- ğŸ’¾ **Session Persistence** - Chat history survives browser refresh
- ğŸ”„ **Auto-Reconnection** - Seamless reconnection on network issues
- ğŸ” **Token-based Security** - Secure session management

### ğŸ¢ï¸ Backend (FastAPI Server)
- ğŸš€ **FastAPI** with automatic OpenAPI documentation
- ğŸ”Œ **WebSocket** support for bidirectional communication
- ğŸ“¡ **Redis Streams** for message queuing and processing
- ğŸ“‹ **Chat History API** - Persistent conversation storage
- ğŸ” **Token Validation** - Secure WebSocket connections
- â° **Session Expiry** - Automatic cleanup (1-hour TTL)
- ğŸŒ **CORS** configured for development and production

### ğŸ› ï¸ Worker (AI Processor)
- ğŸ¤– **Groq Integration** - Groq API for fast AI responses
- ğŸ“¡ **Redis Stream Consumer** - Processes messages asynchronously
- ğŸ“‹ **History Management** - Stores user and AI messages
- ğŸ”„ **Context Awareness** - Uses chat history for better responses
- âš¡ **Async Processing** - Non-blocking AI response generation

### ğŸ¨ Frontend (Next.js Client)
- ğŸ’… **Modern UI** - Glassmorphism design with Tailwind CSS
- ğŸ¦ **Smooth Animations** - Framer Motion for delightful interactions
- ğŸ“± **Responsive Design** - Works perfectly on all devices
- ğŸ“‹ **Markdown Support** - Rich text rendering with syntax highlighting
- ğŸ“ **Session Restoration** - Automatic login and history loading
- ğŸ­ **Loading States** - Professional loading screens and indicators
- ğŸ”” **Toast Notifications** - User feedback for all actions
- ğŸš« **Token Expiration** - Graceful handling of expired sessions

## ğŸš€ Quick Start

### Choose Your Setup Method

**ğŸ³ Docker (Recommended)**: Containerized setup with all dependencies
**ğŸ“¦ Local Setup**: Traditional local development environment

---

## ğŸ³ Docker Setup (Recommended)

### Prerequisites
- **Docker** and **Docker Compose** installed
- **Groq API Key** (free API for AI responses)

### 1. Clone and Configure

```bash
git clone <your-repo-url>
cd fullstack-ai-chatbot

# Copy environment file and edit with your API keys
cp .env-example .env
# Edit .env with your GROQ_API_KEY
```

### 2. Start the Application

```bash
# Start all services (Redis, Server, Worker, Client)
./docker-start.sh

# Or use Docker Compose directly
docker compose up -d --build
```

âœ… **All services will be running**:
- ğŸŒ **Client**: http://localhost:3000
- ğŸš€ **Server**: http://localhost:8000
- ğŸ”´ **Redis**: localhost:6379
- ğŸ“– **API Docs**: http://localhost:8000/docs

### 3. Start Chatting! ğŸ’¬

1. Open http://localhost:3000
2. Click "Get Started"
3. Enter your name
4. Chat with the AI!

### Docker Management Commands

```bash
# Development commands
./docker-start.sh              # Start all services
./docker-start.sh dev          # Development mode with hot reload
./docker-start.sh status       # Show service status and logs
./docker-start.sh logs         # View service logs
./docker-start.sh stop         # Stop all services
./docker-start.sh clean        # Clean up containers and volumes

# Production deployment
docker compose -f docker-compose.prod.yml up -d --wait

# Enable optional services
docker compose -f docker-compose.prod.yml --profile nginx up -d
docker compose -f docker-compose.prod.yml --profile monitoring up -d
```

### Docker Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Docker Network                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Client    â”‚  â”‚   Server    â”‚  â”‚   Worker    â”‚      â”‚
â”‚  â”‚  (Next.js)  â”‚  â”‚  (FastAPI)  â”‚  â”‚ (AI Proc.)  â”‚      â”‚
â”‚  â”‚    :3000    â”‚  â”‚    :8000    â”‚  â”‚             â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                 â”‚                 â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â”‚                              â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                  â”‚    Redis    â”‚                         â”‚
â”‚                  â”‚    :6379    â”‚                         â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Local Setup

### Prerequisites
- **Python 3.8+** with pip
- **Node.js 18+** with npm
- **Redis** instance (local or cloud)
- **Groq API Key** (free API for AI responses)

### 1. Environment Setup

```bash
cd /Users/ashour/Code/Playground/fullstack-ai-chatbot

# Configure server environment
cd server
cp .env.example .env
# Edit .env with your Redis credentials

# Configure worker environment
cd ../worker
cp .env.example .env
# Edit .env with your Groq API key

# Configure client environment
cd ../client
cp .env.local.example .env.local
# Edit with your API URLs
```

### 2. Start the Server (Terminal 1)

```bash
cd server
./start_server.sh
```

âœ… Server runs on `http://localhost:8000`:
- ğŸ  Health: `GET /health`
- ğŸ« Token: `POST /token`
- ğŸ“‹ History: `GET /chat_history`
- ğŸ”Œ WebSocket: `ws://localhost:8000/chat`
- ğŸ“– Docs: `http://localhost:8000/docs`

### 3. Start the Worker (Terminal 2)

```bash
cd worker
python main.py
```

âœ… Worker will consume Redis streams and process AI requests

### 4. Start the Client (Terminal 3)

```bash
cd client
./start_client.sh
```

âœ… Client runs on `http://localhost:3000`

### 5. Start Chatting! ğŸ’¬

1. Open `http://localhost:3000`
2. Click "Get Started"
3. Enter your name
4. Chat with the AI - responses are powered by GPT!
5. Refresh page to test session persistence

## ğŸ› ï¸ Configuration

### Environment Strategy
- **Development**: Local `.env` files for each service
- **Production**: Environment variables via CI/CD secrets
- **Client URLs**: Build-time configuration (cannot change at runtime)

### Environment Files
```bash
.env                    # Root environment (Redis, API keys, CORS)
server/.env            # Server-specific config (optional)
worker/.env            # Worker-specific config (optional)
client/.env.local      # Client-specific config (API URLs)
```

### Production Configuration

#### Required Runtime Secrets
```env
# AI Model Integration
GROQ_API_KEY=your_groq_api_key

# Database Authentication
REDIS_PASSWORD=your_secure_redis_password
REDIS_USER=default

# Security Configuration
CORS_ORIGINS=https://yourdomain.com,http://client:3000
TOKEN_EXPIRY_HOURS=1

# Optional: Monitoring
GRAFANA_ADMIN_PASSWORD=secure_password
```

#### Client Build-Time Variables
```env
# These are baked into the client image at build time
NEXT_PUBLIC_API_URL=https://api.yourdomain.com
NEXT_PUBLIC_WS_URL=wss://api.yourdomain.com
```

### Development Configuration

#### Local Development Setup
```env
# .env (root)
GROQ_API_KEY=your_groq_api_key
REDIS_PASSWORD=dev_password
CORS_ORIGINS=http://localhost:3000,http://client:3000

# client/.env.local
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000
```

### Key Settings
- **Session Duration**: 1 hour (configurable via `TOKEN_EXPIRY_HOURS`)
- **Chat Context**: Last 10 messages sent to AI model
- **Auto-Reconnect**: 3-second delay with exponential backoff
- **Resource Limits**: Optimized for production workloads
- **Health Checks**: 30-second intervals with 3 retries

## ğŸ”„ CI/CD Workflows

### Automated Pipeline Overview

The project includes three main GitHub Actions workflows:

#### 1. Build and Push (`build-and-push.yml`)
**Triggers**: Push to main (after CI success) or version tags (`v*`)
- ğŸ—ï¸ **Multi-architecture builds** (AMD64 + ARM64)
- ğŸ”’ **Security scanning** with SBOM generation
- ğŸ“¦ **Environment-specific client images**
- ğŸ§¹ **Build cache optimization**

#### 2. Deploy to Staging (`deploy-staging.yml`)
**Triggers**: After successful image build on main branch
- ğŸš€ **Automatic deployment** to staging environment
- ğŸ¥ **Health checks** for all services
- ğŸ“¢ **Slack notifications** on success/failure
- ğŸ§¹ **Container cleanup** after deployment

#### 3. Deploy to Production (`deploy-production.yml`)
**Triggers**: Version tag push (`v*`) or manual dispatch
- ğŸ’¾ **Automatic backup** of current deployment
- ğŸ”„ **Zero-downtime rolling deployment**
- ğŸ¥ **Comprehensive health checks**
- ğŸ“¦ **Automatic rollback** on failure
- ğŸ”’ **Production-grade security**

### Workflow Features

#### Image Tagging Strategy
```bash
# Server/Worker (environment-agnostic)
ghcr.io/org/repo/server:latest
ghcr.io/org/repo/server:v1.0.0

# Client (environment-specific)
ghcr.io/org/repo/client:latest-staging
ghcr.io/org/repo/client:v1.0.0-production
```

#### Deployment Safety
- **Staging**: Automatic deployment with health checks
- **Production**: Backup â†’ Deploy â†’ Verify â†’ Rollback on failure
- **Manual Override**: `force_deploy` input to skip health checks

## ğŸ Troubleshooting

### ï¿½ CI/CeD Issues

#### Deployment Failures
```bash
# Check workflow logs in GitHub Actions
# Common issues:
- Missing required secrets (GROQ_API_KEY, SSH keys)
- Health check timeouts (services not ready)
- Image pull failures (registry authentication)

# Manual deployment verification
ssh user@server 'docker compose -f docker-compose.prod.yml ps'
```

#### Image Build Problems
```bash
# Check build logs in GitHub Actions
# Common issues:
- Multi-architecture build failures
- Client environment variable configuration
- Registry authentication issues

# Local build testing
docker buildx build --platform linux/amd64,linux/arm64 ./server
```

#### Rollback Issues
```bash
# Production rollback is automatic on health check failure
# Manual rollback if needed:
ssh user@production-server << 'EOF'
  cd latest_backup
  docker compose -f docker-compose.prod.yml up -d
EOF
```

### ğŸ³ Docker Issues

#### Service Health Checks
```bash
# Check service health status
docker compose ps
docker compose logs [service-name]

# Test individual health endpoints
curl -f http://localhost:8000/health  # Server
curl -f http://localhost:3000         # Client
docker compose exec redis redis-cli -a $REDIS_PASSWORD ping  # Redis
```

#### Environment Configuration
```bash
# Verify environment files
ls -la .env*

# Check loaded environment in containers
docker compose exec server printenv | grep -E "(REDIS|GROQ|CORS)"
docker compose exec worker printenv | grep GROQ_API_KEY
```

#### Resource Issues
```bash
# Check resource usage
docker stats

# Adjust resource limits in docker-compose.prod.yml
services:
  worker:
    deploy:
      resources:
        limits:
          memory: 2G  # Increase if needed
          cpus: "2.0"
```

#### Network Connectivity
```bash
# Test inter-service communication
docker compose exec client curl http://server:8000/health
docker compose exec server redis-cli -h redis -a $REDIS_PASSWORD ping

# Check network configuration
docker network ls
docker network inspect fullstack-ai-chatbot_chatbot-network-prod
```

### ğŸ“¦ Local Development Issues

#### Client URL Problems
```bash
# Client URLs are build-time only - cannot change at runtime
# For local development, ensure client/.env.local has:
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000

# For production, URLs are baked into the image during CI/CD
```

#### Service Communication
```bash
# Internal Docker network communication
docker compose exec client curl http://server:8000/health

# External access (from host)
curl http://localhost:8000/health
curl http://localhost:3000

# WebSocket testing
wscat -c ws://localhost:8000/chat?token=your_token
```

#### Common Solutions
- **Server won't start**: Check Redis connection and GROQ_API_KEY
- **Client build fails**: Verify Node.js version (18+) and run `npm install`
- **WebSocket errors**: Ensure token is valid and not expired
- **CORS errors**: Check CORS_ORIGINS includes your client URL
- **Redis connection**: Verify REDIS_PASSWORD matches in all services
- **AI responses fail**: Confirm GROQ_API_KEY is valid and has credits

#### Performance Optimization
```bash
# Enable Docker BuildKit for faster builds
export DOCKER_BUILDKIT=1

# Use development mode for hot reload
./docker-start.sh dev

# Monitor resource usage
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
```

## ğŸ§ª Testing

### Client Testing
```bash
cd client
npm test                       # Run Jest tests
npm run test:watch            # Watch mode
npm run test:coverage         # Coverage report
```

### Server Testing
```bash
cd server
python -m pytest             # Run Python tests
```

### Worker Testing
```bash
cd worker
python -m pytest             # Run Python tests
```

### Build Commands
```bash
# Client Build
cd client
npm run build                 # Production build with Turbopack
npm run lint                  # ESLint checking

# Docker Build
docker compose build          # Build all services
docker compose up -d --build  # Build and start
```

## ğŸ“¡ API Endpoints

### REST API
- `GET /health` - Health check endpoint
- `POST /token` - Generate chat token (form data: `name`)
- `GET /chat_history?token=<token>` - Retrieve chat history with messages

**Response Codes:**
- `200` - Success
- `400` - Invalid request or expired session
- `500` - Internal server error

### WebSocket
- `ws://localhost:8000/chat?token=<token>` - Real-time bidirectional chat

**Connection Codes:**
- `1000` - Normal closure
- `1008` - Policy violation (invalid/expired token)

## ğŸ¨ UI Components

### Core Components
- **WelcomeModal** - User onboarding with name input
- **SessionRestoreLoader** - Loading screen during session restoration
- **MessageList** - Scrollable chat history with markdown support
- **Message** - Individual message bubble with user/AI styling
- **MessageInput** - Auto-resizing textarea with send button
- **ConnectionStatus** - Real-time connection indicator
- **TypingIndicator** - Animated dots when AI is responding

### Features
- **Markdown Rendering** - Code syntax highlighting, tables, lists
- **Session Persistence** - Automatic login and history restoration
- **Token Expiration** - Graceful session timeout handling
- **Toast Notifications** - User feedback for all actions

## ğŸ”§ Development

### Server Development
```bash
cd server
source .venv/bin/activate
uvicorn main:api --reload --host 0.0.0.0 --port 8000
```

### Client Development
```bash
cd client
npm run dev
```

## ğŸ“š Technologies Used

### Backend Stack
- **FastAPI 0.115.0** - Modern Python web framework with automatic OpenAPI docs
- **Uvicorn** - ASGI server with hot reload support
- **WebSockets 13.1** - Real-time bidirectional communication
- **Redis 5.2.0** - In-memory data store for sessions and message streaming
- **Pydantic 2.10.1** - Data validation and serialization
- **Python-multipart** - Form data handling for token generation

### AI Processing
- **Groq 0.32.0** - AI model integration for GPT responses
- **Redis Streams** - Async message queue processing
- **Python-dotenv** - Environment variable management
- **Asyncio** - Asynchronous programming for performance

### Frontend Stack
- **Next.js 15.5.4** - React framework with App Router and Turbopack
- **React 19.1.0** - Latest React with concurrent features
- **TypeScript 5** - Type-safe development
- **Tailwind CSS 4** - Utility-first styling with custom animations
- **Framer Motion 12.23.21** - Smooth animations and transitions

### UI Libraries
- **React Hot Toast** - Beautiful notification system
- **React Markdown 10.1.0** - Markdown rendering with GFM support
- **Rehype Highlight** - Syntax highlighting for code blocks
- **Lucide React** - Modern icon library

### DevOps & Infrastructure
- **Docker & Docker Compose** - Containerization and orchestration
- **GitHub Actions** - CI/CD pipeline automation
- **GitHub Container Registry** - Multi-architecture image storage
- **Redis Stack Server 7.4.0** - Production-ready Redis with modules
- **Nginx Alpine** - Lightweight reverse proxy (optional)
- **Prometheus & Grafana** - Monitoring and metrics (optional)

### Security & Quality
- **SBOM Generation** - Software Bill of Materials for security
- **Multi-architecture builds** - AMD64 and ARM64 support
- **Health checks** - Comprehensive service monitoring
- **Automatic rollback** - Production deployment safety
- **Resource limits** - Container resource management

## ğŸš€ Deployment

### ğŸ¤– Automated CI/CD Pipeline

**Complete automation from code to production!** The project includes a comprehensive CI/CD pipeline with GitHub Actions:

#### Deployment Flow
```bash
# 1. Push to main â†’ Automatic staging deployment
git push origin main

# 2. Create version tag â†’ Automatic production deployment
git tag v1.0.0
git push origin v1.0.0
```

#### Pipeline Features
- âœ… **Multi-architecture builds** (AMD64 + ARM64)
- ğŸ”’ **Security scanning** with SBOM generation
- ğŸ—ï¸ **Environment-specific client builds** (staging vs production URLs)
- ğŸ”„ **Zero-downtime deployments** with health checks
- ğŸ“¦ **Automatic rollback** on production failures
- ğŸ§¹ **Image cleanup** to manage registry storage
- ğŸ“¢ **Slack notifications** for deployment status

#### Container Registry Strategy
- **Server/Worker**: Environment-agnostic images (`latest`, `v1.0.0`)
- **Client**: Environment-specific builds (`latest-staging`, `v1.0.0-production`)
- **Registry**: GitHub Container Registry (`ghcr.io`)

### ğŸ³ Production Docker Setup

#### Optimized Production Configuration

The `docker-compose.prod.yml` provides enterprise-ready deployment:

```yaml
# Resource-optimized services
server:
  deploy:
    resources:
      limits: { memory: 512M, cpus: "0.5" }
    replicas: 1

worker:
  deploy:
    resources:
      limits: { memory: 1G, cpus: "1.0" }
    replicas: 1

# Health checks for all services
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  interval: 30s
  timeout: 10s
  retries: 3
```

#### Optional Production Services
```bash
# Enable Nginx reverse proxy
docker compose -f docker-compose.prod.yml --profile nginx up -d

# Enable monitoring stack (Prometheus + Grafana)
docker compose -f docker-compose.prod.yml --profile monitoring up -d
```

### ğŸ”§ Manual Deployment (Advanced)

#### Required GitHub Secrets
For automated deployments, configure these secrets in your repository:

```bash
# Staging Environment
STAGING_SSH_PRIVATE_KEY, STAGING_USER, STAGING_HOST
STAGING_GROQ_API_KEY, STAGING_REDIS_PASSWORD
STAGING_API_URL, STAGING_WS_URL

# Production Environment
PRODUCTION_SSH_PRIVATE_KEY, PRODUCTION_USER, PRODUCTION_HOST
PRODUCTION_GROQ_API_KEY, PRODUCTION_REDIS_PASSWORD
PRODUCTION_API_URL, PRODUCTION_WS_URL, PRODUCTION_DOMAIN

# Optional: Slack notifications
SLACK_WEBHOOK_URL
```

#### Manual Production Deployment
```bash
# Set environment variables
export CLIENT_ENV=production
export REGISTRY=ghcr.io
export IMAGE_NAME=your-org/fullstack-ai-chatbot
export IMAGE_TAG=v1.0.0

# Deploy with specific version
docker compose -f docker-compose.prod.yml up -d --wait

# Or deploy staging
export CLIENT_ENV=staging
docker compose -f docker-compose.prod.yml up -d --wait
```

#### Deployment Features
- ğŸ”„ **Automatic rollback** on production health check failures
- ğŸ’¾ **Deployment backups** with timestamp-based restore points
- ğŸ¥ **Comprehensive health checks** for all services
- ğŸ”’ **Secure secrets management** via environment variables
- ğŸ“Š **Resource monitoring** with optional Prometheus/Grafana stack

### ğŸŒ Cloud Platform Support

#### Container Orchestration
- **Docker Swarm**: Use `docker-compose.prod.yml` directly
- **Kubernetes**: Convert with Kompose or use Helm charts
- **AWS ECS/Fargate**: Deploy with task definitions
- **Azure Container Instances**: Use container groups
- **Google Cloud Run**: Deploy individual services

#### Platform-as-a-Service
- **Railway**: Connect GitHub repo for auto-deployment
- **Render**: Use Docker deployment with health checks
- **DigitalOcean App Platform**: Multi-service app configuration

## ğŸ”„ Recent Updates

### ğŸš€ Production-Ready CI/CD Pipeline
- âœ… **Automated deployments** with GitHub Actions
- ğŸ—ï¸ **Multi-architecture builds** (AMD64 + ARM64)
- ğŸ”’ **Security scanning** with SBOM generation
- ğŸ”„ **Zero-downtime deployments** with health checks
- ğŸ“¦ **Automatic rollback** on production failures
- ğŸ§¹ **Container registry cleanup** and optimization

### ğŸ³ Enhanced Docker Infrastructure
- ğŸ¥ **Comprehensive health checks** for all services
- ğŸ“Š **Resource limits** and performance optimization
- ğŸ”§ **Optional services** (Nginx proxy, monitoring stack)
- ğŸŒ **Production networking** with custom subnets
- ğŸ’¾ **Persistent volumes** for data retention

### ğŸ¨ Application Features
- âœ¨ **Session Persistence** - Automatic login restoration
- ğŸ“‹ **Chat History** - Complete conversation storage
- ğŸ“ **Markdown Support** - Rich text with syntax highlighting
- ğŸ” **Token Security** - Proper expiration handling
- ğŸ­ **UI Polish** - Loading states and smooth animations
- ğŸ”„ **Auto-reconnection** - Seamless network recovery

## ğŸ“œ Documentation

- **Server API**: `http://localhost:8000/docs` (FastAPI auto-docs)
- **Architecture**: Microservices with Redis message streaming
- **Security**: Token-based sessions with 1-hour expiry
- **Persistence**: localStorage + Redis for full session restoration

## ğŸ“ License

MIT License - feel free to use this project as a foundation for your own AI chatbots!

---
