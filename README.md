# ğŸ¤– Full-Stack AI Chatbot

A modern, production-ready AI chatbot application featuring real-time messaging, session persistence, and AI-powered responses. Built with FastAPI backend, Next.js frontend, and Redis-based message streaming architecture.

## ğŸ¢ï¸ Architecture

This is a **microservices architecture** with three main components:

```
fullstack-ai-chatbot/
â”œâ”€â”€ server/                # FastAPI API Server
â”‚   â”œâ”€â”€ main.py            # FastAPI app with CORS
â”‚   â”œâ”€â”€ src/               # Source code
â”‚   â”‚   â”œâ”€â”€ routes/        # API routes (token, chat_history, websocket)
â”‚   â”‚   â”œâ”€â”€ redis/         # Redis integration (streams, cache)
â”‚   â”‚   â”œâ”€â”€ socket/        # WebSocket management & token validation
â”‚   â”‚   â””â”€â”€ schema/        # Pydantic data models
â”‚   â”œâ”€â”€ start_server.sh    # Server startup script
â”‚   â””â”€â”€ requirements.txt   # Python dependencies
â”‚
â”œâ”€â”€ worker/                # AI Processing Worker
â”‚   â”œâ”€â”€ main.py            # Worker process for AI responses
â”‚   â”œâ”€â”€ src/               # Source code
â”‚   â”‚   â”œâ”€â”€ model/         # AI model integration (GPT)
â”‚   â”‚   â”œâ”€â”€ redis/         # Redis streams & cache
â”‚   â”‚   â””â”€â”€ schema/        # Shared data models
â”‚   â””â”€â”€ requirements.txt   # Python dependencies
â”‚
â””â”€â”€ client/                # Next.js Frontend (generated by claude code)
    â”œâ”€â”€ src/               # Source code
    â”‚   â”œâ”€â”€ app/           # Next.js app directory
    â”‚   â”œâ”€â”€ components/    # React components
    â”‚   â”œâ”€â”€ hooks/         # Custom React hooks (useChat)
    â”‚   â”œâ”€â”€ lib/           # Utilities & session management
    â”‚   â””â”€â”€ types/         # TypeScript types
    â”œâ”€â”€ start_client.sh    # Client startup script
    â””â”€â”€ package.json       # Node.js dependencies
```

### ğŸ“‹ Data Flow
1. **Client** sends message via WebSocket â†’ **Server**
2. **Server** publishes to Redis stream â†’ **Worker**
3. **Worker** processes with AI model â†’ publishes response â†’ **Server**
4. **Server** sends AI response â†’ **Client**
5. **Worker** stores both messages in Redis for chat history

## âœ¨ Features

### ğŸš€ Core Functionality
- ğŸ¤– **AI-Powered Responses** - Real AI model integration with GPT
- âš¡ **Real-time Messaging** - Instant WebSocket communication
- ğŸ’¾ **Session Persistence** - Chat history survives browser refresh
- ğŸ”„ **Auto-Reconnection** - Seamless reconnection on network issues
- ğŸ” **Token-based Security** - Secure session management

### ğŸ¢ï¸ Backend (FastAPI Server)
- ğŸš€ **FastAPI** with automatic OpenAPI documentation
- ğŸ”Œ **WebSocket** support for bidirectional communication
- ğŸ“¡ **Redis Streams** for message queuing and processing
- ğŸ“‹ **Chat History API** - Persistent conversation storage
- ğŸ” **Token Validation** - Secure WebSocket connections
- â° **Session Expiry** - Automatic cleanup (1-hour TTL)
- ğŸŒ **CORS** configured for development and production

### ğŸ› ï¸ Worker (AI Processor)
- ğŸ¤– **GPT Integration** - OpenAI API for AI responses
- ğŸ“¡ **Redis Stream Consumer** - Processes messages asynchronously
- ğŸ“‹ **History Management** - Stores user and AI messages
- ğŸ”„ **Context Awareness** - Uses chat history for better responses
- âš¡ **Async Processing** - Non-blocking AI response generation

### ğŸ¨ Frontend (Next.js Client)
- ğŸ’… **Modern UI** - Glassmorphism design with Tailwind CSS
- ğŸ¦ **Smooth Animations** - Framer Motion for delightful interactions
- ğŸ“± **Responsive Design** - Works perfectly on all devices
- ğŸ“‹ **Markdown Support** - Rich text rendering with syntax highlighting
- ğŸ“ **Session Restoration** - Automatic login and history loading
- ğŸ­ **Loading States** - Professional loading screens and indicators
- ğŸ”” **Toast Notifications** - User feedback for all actions
- ğŸš« **Token Expiration** - Graceful handling of expired sessions

## ğŸš€ Quick Start

### Choose Your Setup Method

**ğŸ³ Docker (Recommended)**: Containerized setup with all dependencies
**ğŸ“¦ Local Setup**: Traditional local development environment

---

## ğŸ³ Docker Setup (Recommended)

### Prerequisites
- **Docker** and **Docker Compose** installed
- **Groq API Key** (free API for AI responses)

### 1. Clone and Configure

```bash
git clone <your-repo-url>
cd fullstack-ai-chatbot

# Copy environment file and edit with your API keys
cp .env.docker .env
# Edit .env with your GROQ_API_KEY
```

### 2. Start the Application

```bash
# Start all services (Redis, Server, Worker, Client)
./docker-start.sh

# Or use Docker Compose directly
docker compose up -d --build
```

âœ… **All services will be running**:
- ğŸŒ **Client**: http://localhost:3000
- ğŸš€ **Server**: http://localhost:8000
- ğŸ”´ **Redis**: localhost:6379
- ğŸ“– **API Docs**: http://localhost:8000/docs

### 3. Start Chatting! ğŸ’¬

1. Open http://localhost:3000
2. Click "Get Started"
3. Enter your name
4. Chat with the AI!

### Docker Management Commands

```bash
# Show service status and logs
./docker-start.sh status
./docker-start.sh logs

# Restart services
./docker-start.sh restart

# Stop all services
./docker-start.sh stop

# Development mode (with hot reload)
./docker-start.sh dev

# Clean up everything
./docker-start.sh clean
```

### Docker Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Docker Network                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Client    â”‚  â”‚   Server    â”‚  â”‚   Worker    â”‚      â”‚
â”‚  â”‚  (Next.js)  â”‚  â”‚  (FastAPI)  â”‚  â”‚ (AI Proc.)  â”‚      â”‚
â”‚  â”‚    :3000    â”‚  â”‚    :8000    â”‚  â”‚             â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                 â”‚                 â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â”‚                              â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                  â”‚    Redis    â”‚                         â”‚
â”‚                  â”‚    :6379    â”‚                         â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Local Setup

### Prerequisites
- **Python 3.8+** with pip
- **Node.js 18+** with npm
- **Redis** instance (local or cloud)
- **Groq API Key** (free API for AI responses)

### 1. Environment Setup

```bash
cd /Users/ashour/Code/Playground/fullstack-ai-chatbot

# Configure server environment
cd server
cp .env.example .env
# Edit .env with your Redis credentials

# Configure worker environment
cd ../worker
cp .env.example .env
# Edit .env with your OpenAI API key

# Configure client environment
cd ../generated-client
cp .env.local.example .env.local
# Edit with your API URLs
```

### 2. Start the Server (Terminal 1)

```bash
cd server
./start_server.sh
```

âœ… Server runs on `http://localhost:8000`:
- ğŸ  Health: `GET /test`
- ğŸ« Token: `POST /token`
- ğŸ“‹ History: `GET /chat_history`
- ğŸ”Œ WebSocket: `ws://localhost:8000/chat`
- ğŸ“– Docs: `http://localhost:8000/docs`

### 3. Start the Worker (Terminal 2)

```bash
cd worker
python main.py
```

âœ… Worker will consume Redis streams and process AI requests

### 4. Start the Client (Terminal 3)

```bash
cd generated-client
./start_client.sh
```

âœ… Client runs on `http://localhost:3000`

### 5. Start Chatting! ğŸ’¬

1. Open `http://localhost:3000`
2. Click "Get Started"
3. Enter your name
4. Chat with the AI - responses are powered by GPT!
5. Refresh page to test session persistence

## ğŸ› ï¸ Configuration

### Server Configuration

Edit `server/.env`:
```env
APP_ENV=development
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_USER=default
REDIS_PASSWORD=your_redis_password
CORS_ORIGINS=http://localhost:3000,http://client:3000
```

### Worker Configuration

Edit `worker/.env`:
```env
GROQ_API_KEY=your_groq_api_key
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_USER=default
REDIS_PASSWORD=your_redis_password
```

### Client Configuration

Edit `client/.env.local`:
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000
```

### Session Configuration
- **Session Duration**: 1 hour (configurable in server Redis TTL)
- **Chat History Limit**: Last 10 messages sent to AI for context
- **Auto-Reconnect**: 3-second delay with exponential backoff

## ğŸ Troubleshooting

### ğŸ³ Docker Issues

#### Service Won't Start
```bash
# Check service logs
docker compose logs [service-name]

# Check service status
docker compose ps

# Restart specific service
docker compose restart [service-name]
```

#### Environment Variables
```bash
# Verify environment file exists
ls -la .env

# Check loaded environment in container
docker compose exec server printenv | grep API
```

#### Port Conflicts
```bash
# Check what's using ports
lsof -i :3000
lsof -i :8000
lsof -i :6379

# Stop conflicting services
./docker-start.sh stop
```

#### Redis Connection Issues
```bash
# Test Redis connectivity
docker compose exec redis redis-cli ping

# Check Redis logs
docker compose logs redis
```

#### Build Issues
```bash
# Clear Docker cache and rebuild
./docker-start.sh clean
docker system prune -a
./docker-start.sh rebuild
```

### ğŸ“¦ Local Setup Issues

#### CORS Issues
- âœ… **Fixed**: CORS is now properly configured for development
- ğŸ”§ The server allows all origins in development mode
- ğŸ”’ Production mode has restrictive CORS settings

#### Connection Issues
```bash
# Test server connection
curl http://localhost:8000/health

# Test token generation
curl -X POST -F "name=TestUser" http://localhost:8000/token
```

#### Common Solutions
- **Server won't start**: Check Redis connection and credentials
- **Client can't connect**: Ensure server is running first
- **WebSocket errors**: Verify token is valid and not expired
- **Build errors**: Run `npm install` in client directory
- **API Key errors**: Check GROQ_API_KEY in environment file

## ğŸ§ª Testing

### Test Server
```bash
cd server
source .venv/bin/activate
python test_server.py
```

### Test Client Build
```bash
cd generated-client
npm run build
```

## ğŸ“¡ API Endpoints

### REST API
- `GET /test` - Health check endpoint
- `POST /token` - Generate chat token (form data: `name`)
- `GET /chat_history?token=<token>` - Retrieve chat history with messages

**Response Codes:**
- `200` - Success
- `400` - Invalid request or expired session
- `500` - Internal server error

### WebSocket
- `ws://localhost:8000/chat?token=<token>` - Real-time bidirectional chat

**Connection Codes:**
- `1000` - Normal closure
- `1008` - Policy violation (invalid/expired token)

## ğŸ¨ UI Components

### Core Components
- **WelcomeModal** - User onboarding with name input
- **SessionRestoreLoader** - Loading screen during session restoration
- **MessageList** - Scrollable chat history with markdown support
- **Message** - Individual message bubble with user/AI styling
- **MessageInput** - Auto-resizing textarea with send button
- **ConnectionStatus** - Real-time connection indicator
- **TypingIndicator** - Animated dots when AI is responding

### Features
- **Markdown Rendering** - Code syntax highlighting, tables, lists
- **Session Persistence** - Automatic login and history restoration
- **Token Expiration** - Graceful session timeout handling
- **Toast Notifications** - User feedback for all actions

## ğŸ”§ Development

### Server Development
```bash
cd server
source .venv/bin/activate
uvicorn main:api --reload --host 0.0.0.0 --port 8000
```

### Client Development
```bash
cd generated-client
npm run dev
```

## ğŸ“š Technologies Used

### Backend (Server)
- **FastAPI** - Modern Python web framework with auto docs
- **Redis** - In-memory data store for sessions and streaming
- **WebSockets** - Real-time bidirectional communication
- **Pydantic** - Data validation with `Field(default_factory=...)`
- **Uvicorn** - High-performance ASGI web server

### AI Worker
- **OpenAI GPT** - AI model for intelligent responses
- **Redis Streams** - Message queue processing
- **Asyncio** - Asynchronous programming for performance
- **Context Management** - Chat history for better responses

### Frontend (Client)
- **Next.js 14** - React framework with App Router
- **TypeScript** - Type-safe development
- **Tailwind CSS** - Utility-first styling with custom animations
- **Framer Motion** - Smooth animations and transitions
- **React Hot Toast** - Beautiful notification system
- **React Markdown** - Markdown rendering with syntax highlighting
- **Lucide React** - Modern icon library

## ğŸš€ Deployment

### ğŸ³ Docker Deployment (Recommended)

#### Quick Production Deployment

```bash
# 1. Prepare production files
./docker-deploy.sh staging latest prepare

# 2. Configure environment
cp .env.production.template .env.production
# Edit .env.production with your production values

# 3. Deploy to staging
./docker-deploy.sh staging v1.0.0 deploy

# 4. Deploy to production
./docker-deploy.sh production v1.0.0 deploy
```

#### Docker Compose Production

The deployment script creates an optimized `docker-compose.prod.yml` with:
- **Resource limits** for each service
- **Health checks** for all containers
- **Restart policies** for high availability
- **Multi-replica scaling** for server and worker
- **Production-ready** Redis configuration

```yaml
services:
  server:
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1gb
          cpus: '1.0'

  worker:
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1gb
          cpus: '1.0'
```

#### Container Registry

```bash
# Build and push to your registry
export DOCKER_REGISTRY=your-registry.com
./docker-deploy.sh production v1.0.0 build
./docker-deploy.sh production v1.0.0 push
```

### ğŸ“¦ Manual Deployment

#### Server
```bash
# Production environment
export APP_ENV=production
export REDIS_URL=your_production_redis

# Use Gunicorn + Uvicorn for production
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

#### Worker
```bash
# Ensure Groq API key is set
export GROQ_API_KEY=your_production_key

# Run worker with process manager (PM2, systemd, etc.)
python main.py
```

#### Client
```bash
# Build optimized bundle
npm run build

# Deploy to Vercel/Netlify/etc.
# Update API URLs for production
```

### ğŸŒ Cloud Deployment Options

#### Docker Swarm
```bash
# Initialize swarm
docker swarm init

# Deploy stack
docker stack deploy -c docker-compose.prod.yml chatbot
```

#### Kubernetes
```bash
# Convert docker-compose to k8s (using kompose)
kompose convert -f docker-compose.prod.yml
kubectl apply -f .
```

#### AWS ECS / Azure Container Instances
- Use the production Docker images
- Configure environment variables
- Set up load balancer for multiple replicas

## ğŸ”„ Recent Updates

- âœ¨ **Session Persistence** - Automatic login restoration
- ğŸ“‹ **Chat History** - Complete conversation storage
- ğŸ“ **Markdown Support** - Rich text with syntax highlighting
- ğŸ” **Token Security** - Proper expiration handling
- ğŸ¨ **UI Polish** - Loading states and animations
- ğŸ› **Bug Fixes** - UUID generation, scrollbar behavior

## ğŸ“œ Documentation

- **Server API**: `http://localhost:8000/docs` (FastAPI auto-docs)
- **Architecture**: Microservices with Redis message streaming
- **Security**: Token-based sessions with 1-hour expiry
- **Persistence**: localStorage + Redis for full session restoration

## ğŸ“ License

MIT License - feel free to use this project as a foundation for your own AI chatbots!

---
